{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'qdrug' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n qdrug ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import tqdm\n",
    "\n",
    "from qumedl.mol.encoding.selfies_ import Selfies\n",
    "from qumedl.models.transformer.pat import CausalMolPAT\n",
    "from qumedl.models.transformer.loss_functions import causal_transformer_compute_losses\n",
    "from qumedl.training.collator import CollatorForCausalModeling\n",
    "from qumedl.training.tensor_batch import TensorBatch\n",
    "from qumedl.models.activations import NewGELU\n",
    "from qumedl.models.priors import GaussianPrior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "DEVICE =  \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "batch_size = 32\n",
    "prior_dim = 16\n",
    "\n",
    "model_dim = embedding_dim = 128\n",
    "n_attn_heads = 4\n",
    "n_encoder_layers = 4\n",
    "dropout = 0.2\n",
    "\n",
    "n_epochs = 2\n",
    "learning_rate = 0.001\n",
    "gradient_accumulation_steps = 4\n",
    "\n",
    "n_test_samples = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 2230.08it/s]\n"
     ]
    }
   ],
   "source": [
    "selfies = Selfies.from_smiles_csv(\n",
    "    \"/root/data/drug-discovery/1Kstoned_vsc_initial_dataset_insilico_chemistry42_filtered.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/qumedl/lib/python3.11/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.activation_relu_or_gelu was not True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "/opt/conda/envs/qumedl/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "selfies_dataset = selfies.as_dataset()\n",
    "\n",
    "dl_shuffler = torch.Generator()\n",
    "dl_shuffler.manual_seed(random_seed)\n",
    "\n",
    "selfies_dl = DataLoader(\n",
    "    selfies_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    generator=dl_shuffler,\n",
    "    collate_fn=CollatorForCausalModeling(),\n",
    ")\n",
    "\n",
    "prior = GaussianPrior(dim=prior_dim)\n",
    "\n",
    "model = CausalMolPAT(\n",
    "    vocab_size=selfies.n_tokens,\n",
    "    embedding_dim=embedding_dim,\n",
    "    prior_dim=prior.dim,\n",
    "    model_dim=model_dim,\n",
    "    n_attn_heads=n_attn_heads,\n",
    "    n_encoder_layers=n_encoder_layers,\n",
    "    hidden_act=NewGELU(),\n",
    "    dropout=dropout,\n",
    "    padding_token_idx=selfies.pad_index,\n",
    ")\n",
    "\n",
    "model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model: 100%|██████████| 32/32 [00:03<00:00,  8.81it/s, total_loss=1.09] \n",
      "Training Model: 100%|██████████| 32/32 [00:02<00:00, 13.54it/s, total_loss=0.833]\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "for epoch in range(n_epochs):\n",
    "    with tqdm.tqdm(total=len(selfies_dl), desc=\"Training Model\") as prog_bar:\n",
    "        tensor_batch: TensorBatch\n",
    "        for step, tensor_batch in enumerate(selfies_dl):\n",
    "            tensor_batch.to(DEVICE)\n",
    "            prior_samples = prior.generate(tensor_batch.batch_size).to(DEVICE)\n",
    "            total_loss = causal_transformer_compute_losses(\n",
    "                model, tensor_batch, prior_samples=prior_samples\n",
    "            )\n",
    "\n",
    "            total_loss.backward()\n",
    "\n",
    "            if step % gradient_accumulation_steps == 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            step_losses = {\"total_loss\": total_loss.item()}\n",
    "\n",
    "            prog_bar.set_postfix(step_losses)\n",
    "            prog_bar.update()\n",
    "\n",
    "            tensor_batch.to(\"cpu\")\n",
    "            prior_samples.to(\"cpu\")\n",
    "\n",
    "    prog_bar.set_description(\"Generating test molecules\")\n",
    "\n",
    "    # generate a few samples and save them as JSON locally and to WandB\n",
    "    test_prior_samples = prior.generate(n_test_samples).to(DEVICE)\n",
    "    start_tokens = torch.full(\n",
    "        (n_test_samples, 1),\n",
    "        fill_value=selfies.start_index,\n",
    "        device=DEVICE,\n",
    "        dtype=torch.int,\n",
    "    )\n",
    "\n",
    "    generated = model.generate(\n",
    "        start_tokens, test_prior_samples, max_new_tokens=selfies.max_length\n",
    "    )\n",
    "    test_molecules = selfies.decode(generated.cpu().numpy())\n",
    "    \n",
    "    # UNCOMMENT to save samples as JSON\n",
    "    # with open(f\"test_molecules-{epoch}.json\", \"w\") as f:\n",
    "    #     json.dump(test_molecules, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_tokens = torch.full(\n",
    "    (5, 1),\n",
    "    fill_value=selfies.start_index,\n",
    "    device=DEVICE,\n",
    "    dtype=torch.int,\n",
    ")\n",
    "\n",
    "prior_samples = prior.generate(start_tokens.shape[0]).to(DEVICE)\n",
    "\n",
    "generated_samples = model.generate(start_tokens, prior_samples, max_new_tokens=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[25,  9, 11,  9,  9, 11,  9,  9,  9,  9,  9],\n",
       "         [25,  9,  9,  9,  9, 11,  9, 11,  9,  9,  9],\n",
       "         [25,  9,  9,  9, 24, 11,  9,  9,  9,  9,  9],\n",
       "         [25, 11,  9,  9, 11,  9,  9,  9,  9,  9, 11],\n",
       "         [25,  9,  9, 11,  9,  9,  9,  9,  9, 11,  9]], device='cuda:0'),\n",
       " 9)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_samples, selfies.pad_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '', '', '[C]', '']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selfies.decode(generated_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qumedl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
